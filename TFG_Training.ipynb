{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "d8b6L0fN_GlD"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import model\n",
        "import dataset\n",
        "from src.utils import set_logger, get_pck_with_sigma, get_pred_coordinates\n",
        "from src.loss import sum_mse_loss\n",
        "from easydict import EasyDict as edict\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "erMWpkge_NrD"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "************** Experiment Name: EXP_Panoptic_ARB **************\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "the log directory exists!\n"
          ]
        }
      ],
      "source": [
        "# ***********************  Parameter  ***********************\n",
        "\n",
        "args = edict({\n",
        "    \"config_file\": 'data_sample/Panoptic_base.json',\n",
        "    \"GPU\": 0\n",
        "})\n",
        "configs = json.load(open(args.config_file)) # type: ignore\n",
        "\n",
        "target_sigma_list = [0.05, 0.1, 0.15, 0.2, 0.25]\n",
        "select_sigma = 0.15\n",
        "\n",
        "model_name = 'EXP_' + configs[\"name\"]\n",
        "torch.cuda.empty_cache()\n",
        "save_dir = os.path.join(model_name, 'checkpoint/')\n",
        "test_pck_dir = os.path.join(model_name, 'test/')\n",
        "\n",
        "if os.path.exists(model_name):\n",
        "    print(\"the log directory exists!\")\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "os.makedirs(test_pck_dir, exist_ok=True)\n",
        "\n",
        "# training parameters ****************************\n",
        "data_root = configs[\"data_root\"]\n",
        "learning_rate = configs[\"learning_rate\"]\n",
        "batch_size = configs[\"batch_size\"]\n",
        "epochs = configs[\"epochs\"]\n",
        "# data parameters ****************************\n",
        "\n",
        "\n",
        "cuda = torch.cuda.is_available()\n",
        "\n",
        "\n",
        "logger = set_logger(os.path.join(model_name, 'train.log'))\n",
        "logger.info(\"************** Experiment Name: {} **************\".format(model_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "x2-spsNG_j0k"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Create Model ...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "the number of params: {'Total': 1945122, 'Trainable': 1945122}\n"
          ]
        }
      ],
      "source": [
        "# ******************** build model ********************\n",
        "logger.info(\"Create Model ...\")\n",
        "\n",
        "model = model.light_Model(configs)\n",
        "if cuda:\n",
        "    model = model.cuda()\n",
        "\n",
        "def get_parameter_number(model):\n",
        "    total_num = sum(p.numel() for p in model.parameters())\n",
        "    trainable_num = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    # for name, p in model.named_parameters():\n",
        "    #     if p.requires_grad:\n",
        "    #         print(name, p.numel())\n",
        "    return {'Total': total_num, 'Trainable': trainable_num}\n",
        "print('the number of params:', get_parameter_number(model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "yjMhX0zH_piP"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Total images in training data is 11853\n",
            "Total images in validation data is 1482\n",
            "Total images in testing data is 1482\n"
          ]
        }
      ],
      "source": [
        "# ******************** data preparation  ********************\n",
        "my_dataset = getattr(dataset, configs[\"dataset\"])\n",
        "train_data = my_dataset(data_root=data_root, mode='train')\n",
        "valid_data = my_dataset(data_root=data_root, mode='valid')\n",
        "test_data = my_dataset(data_root=data_root, mode='test')\n",
        "logger.info('Total images in training data is {}'.format(len(train_data)))\n",
        "logger.info('Total images in validation data is {}'.format(len(valid_data)))\n",
        "logger.info('Total images in testing data is {}'.format(len(test_data)))\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=8, shuffle=True)\n",
        "valid_loader = DataLoader(valid_data, batch_size=8, shuffle=False)\n",
        "test_loader = DataLoader(test_data, batch_size=8, shuffle=False)\n",
        "\n",
        "\n",
        "# ********************  ********************\n",
        "optimizer = optim.Adam(params=model.parameters(), lr=learning_rate)\n",
        "# optimizer = optim.SGD(model.parameters(), lr = learning_rate, momentum=0.0)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3, threshold=0.00001, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08, verbose=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "u7c1-FI9_vKz"
      },
      "outputs": [],
      "source": [
        "def plot_loss(train_losses, valid_losses):\n",
        "    epochs = np.arange(1, len(train_losses) + 1)\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, train_losses, label='Train Loss')\n",
        "    plt.plot(epochs, valid_losses, label='Valid Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.legend()\n",
        "    plt.xticks(epochs)\n",
        "    plt.show()\n",
        "\n",
        "def plot_pck(pck_values):\n",
        "    epochs = np.arange(1, len(pck_values) + 1)\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, pck_values)\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('PCK')\n",
        "    plt.title('PCK Evolution')\n",
        "    plt.xticks(epochs)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Q2wDFUxu_zFP"
      },
      "outputs": [],
      "source": [
        "train_losses = []\n",
        "valid_losses = []\n",
        "pck_values = []\n",
        "with open('train_losses.pkl', 'rb') as train_losses_file:\n",
        "    train_losses = pickle.load(train_losses_file)\n",
        "with open('valid_losses.pkl', 'rb') as valid_losses_file:\n",
        "    valid_losses = pickle.load(valid_losses_file)\n",
        "with open('pck_values.pkl', 'rb') as pck_values_file:\n",
        "    pck_values = pickle.load(pck_values_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "hNpKU_vCAPPx"
      },
      "outputs": [],
      "source": [
        "def train(model):\n",
        "    logger.info('\\nStart training ===========================================>')\n",
        "    best_epo = -1\n",
        "    max_pck = -1\n",
        "    logger.info('Initial learning Rate: {}'.format(learning_rate))\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        logger.info('Epoch[{}/{}] ==============>'.format(epoch, epochs))\n",
        "        train_label_loss = []\n",
        "        model.train()\n",
        "        for step, data in enumerate(train_loader, 0):\n",
        "            # *************** target prepare ***************\n",
        "            img, label_terget, img_name, w, h = data\n",
        "            if cuda:\n",
        "                img = img.cuda(non_blocking=True)\n",
        "                label_terget = label_terget.cuda(non_blocking=True)\n",
        "            optimizer.zero_grad()\n",
        "            label_pred = model(img)\n",
        "\n",
        "            # *************** calculate loss ***************\n",
        "            label_loss = sum_mse_loss(label_pred.float(), label_terget.float())  # keypoint confidence loss\n",
        "            label_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_label_loss.append(label_loss.item())\n",
        "\n",
        "            label_loss.detach()\n",
        "\n",
        "            if step % 10 == 0:\n",
        "                logger.info('TRAIN STEP: {}  LOSS {}'.format(step, label_loss.item()))\n",
        "\n",
        "        # *************** eval model after one epoch ***************\n",
        "        eval_loss, cur_pck = eval(model, epoch, mode='valid') # type: ignore\n",
        "        train_losses.append(sum(train_label_loss) / len(train_label_loss))\n",
        "        valid_losses.append(eval_loss)\n",
        "        pck_values.append(cur_pck)\n",
        "        logger.info('EPOCH {} VALID PCK  {}'.format(epoch, cur_pck))\n",
        "        logger.info('EPOCH {} TRAIN_LOSS {}'.format(epoch, sum(train_label_loss) / len(train_label_loss)))\n",
        "        logger.info('EPOCH {} VALID_LOSS {}'.format(epoch, eval_loss))\n",
        "\n",
        "        # *************** save current model and best model ***************\n",
        "        if cur_pck > max_pck:\n",
        "            torch.save(model.state_dict(), os.path.join(save_dir, 'best_model.pth'))\n",
        "            torch.save(optimizer.state_dict(),  os.path.join(save_dir,'best_optimizador.pth'))\n",
        "            best_epo = epoch\n",
        "            max_pck = cur_pck\n",
        "        logger.info('Current Best EPOCH is : {}, PCK is : {}\\n**************\\n'.format(best_epo, max_pck))\n",
        "\n",
        "        # save current model\n",
        "        torch.save(model.state_dict(), os.path.join(save_dir, 'epoch_' + str(epoch) + '_' + str(cur_pck) + '.pth'))\n",
        "        torch.save(optimizer.state_dict(),  os.path.join(save_dir,'epoch_' + str(epoch) + str(cur_pck) + '_''optimizador.pth'))\n",
        "        # scheduler\n",
        "        scheduler.step(cur_pck)\n",
        "\n",
        "    logger.info('Train Done! ')\n",
        "    logger.info('Best epoch is {}'.format(best_epo))\n",
        "    logger.info('Best Valid PCK is {}'.format(max_pck))\n",
        "\n",
        "\n",
        "def eval(model, mode='valid'):\n",
        "    if mode == 'valid':\n",
        "        loader = valid_loader\n",
        "        gt_labels = valid_data.all_labels\n",
        "    else:\n",
        "        loader = test_loader\n",
        "        gt_labels = test_data.all_labels\n",
        "\n",
        "    with torch.no_grad():\n",
        "        all_pred_labels = {}  # save predict results\n",
        "        eval_loss = []\n",
        "        model.eval()\n",
        "        for step, (img, label_terget, img_name, w, h) in enumerate(loader):\n",
        "            if cuda:\n",
        "                img = img.cuda(non_blocking=True)\n",
        "            cm_pred = model(img)\n",
        "\n",
        "            all_pred_labels = get_pred_coordinates(cm_pred.cpu(), img_name, w, h, all_pred_labels)\n",
        "            loss_final = sum_mse_loss(cm_pred.cpu(), label_terget)\n",
        "            if step % 10 == 0:\n",
        "                logger.info('EVAL STEP: {}  LOSS {}'.format(step, loss_final.item()))\n",
        "            eval_loss.append(loss_final)\n",
        "\n",
        "        # ************* calculate PCKs  ************\n",
        "        pck_dict = get_pck_with_sigma(all_pred_labels, gt_labels, target_sigma_list)\n",
        "\n",
        "        select_pck = pck_dict[select_sigma]\n",
        "        eval_loss = sum(eval_loss) / len(eval_loss)\n",
        "    return eval_loss, select_pck\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "wyyTCeo8_3Jw"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Start training ===========================================>\n",
            "Initial learning Rate: 0.0001\n",
            "Epoch[1/5] ==============>\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train(model)\n\u001b[1;32m      2\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mTESTING ============================>\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39mLoad Trained model !!!\u001b[39m\u001b[39m'\u001b[39m)\n",
            "Cell \u001b[0;32mIn[28], line 18\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     16\u001b[0m     label_terget \u001b[39m=\u001b[39m label_terget\u001b[39m.\u001b[39mcuda(non_blocking\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     17\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 18\u001b[0m label_pred \u001b[39m=\u001b[39m model(img)\n\u001b[1;32m     20\u001b[0m \u001b[39m# *************** calculate loss ***************\u001b[39;00m\n\u001b[1;32m     21\u001b[0m label_loss \u001b[39m=\u001b[39m sum_mse_loss(label_pred\u001b[39m.\u001b[39mfloat(), label_terget\u001b[39m.\u001b[39mfloat())  \u001b[39m# keypoint confidence loss\u001b[39;00m\n",
            "File \u001b[0;32m~/VsProjects/TFG-DENSENET/densenet/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/VsProjects/TFG-DENSENET/model/__init__.py:145\u001b[0m, in \u001b[0;36mlight_Model.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, inputs):\n\u001b[0;32m--> 145\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdense1(inputs)\n\u001b[1;32m    146\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransition1(x)\n\u001b[1;32m    147\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdense2(x)\n",
            "File \u001b[0;32m~/VsProjects/TFG-DENSENET/densenet/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/VsProjects/TFG-DENSENET/model/__init__.py:89\u001b[0m, in \u001b[0;36mDense.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     87\u001b[0m x_list \u001b[39m=\u001b[39m [inputs]\n\u001b[1;32m     88\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39miteration):\n\u001b[0;32m---> 89\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49marb[i](inputs)\n\u001b[1;32m     90\u001b[0m     x_list \u001b[39m=\u001b[39m x_list \u001b[39m+\u001b[39m [inputs]\n\u001b[1;32m     91\u001b[0m     inputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat(x_list, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
            "File \u001b[0;32m~/VsProjects/TFG-DENSENET/densenet/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/VsProjects/TFG-DENSENET/model/__init__.py:73\u001b[0m, in \u001b[0;36mARB.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     71\u001b[0m     augmented_conv \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattention_aug(x)\n\u001b[1;32m     72\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39madd(augmented_conv, x)\n\u001b[0;32m---> 73\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv2(x)\n\u001b[1;32m     74\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
            "File \u001b[0;32m~/VsProjects/TFG-DENSENET/densenet/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/VsProjects/TFG-DENSENET/densenet/lib/python3.8/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
            "File \u001b[0;32m~/VsProjects/TFG-DENSENET/densenet/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/VsProjects/TFG-DENSENET/densenet/lib/python3.8/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
            "File \u001b[0;32m~/VsProjects/TFG-DENSENET/densenet/lib/python3.8/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "train(model)\n",
        "logger.info('\\nTESTING ============================>')\n",
        "logger.info('Load Trained model !!!')\n",
        "state_dict = torch.load(os.path.join(save_dir, 'best_model.pth'))\n",
        "model.load_state_dict(state_dict)\n",
        "eval(model, mode='test')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MqMtLmvR0yp1"
      },
      "source": [
        "Guardamos los valores de la función de pérdida y el pck"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Oa7AKn2b0yAo"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('train_losses.pkl', 'wb') as train_losses_file:\n",
        "    pickle.dump(train_losses, train_losses_file)\n",
        "with open('valid_losses.pkl', 'wb') as valid_losses_file:\n",
        "    pickle.dump(valid_losses, valid_losses_file)\n",
        "with open('pck_values.pkl', 'wb') as pck_values_file:\n",
        "    pickle.dump(pck_values, pck_values_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7yASeHBZAa6K"
      },
      "outputs": [],
      "source": [
        "plot_loss(train_losses, valid_losses)\n",
        "plot_pck(pck_values)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "uloRKf2jAAtN"
      },
      "source": [
        "# Pruebas"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "BHuz1onq4Ebc"
      },
      "source": [
        "Comprobamos que la red neuronal realiza predicciones correctas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "em-096s4STth"
      },
      "outputs": [],
      "source": [
        "COLORMAP = {\n",
        "    \"thumb\": {\"ids\": [0, 1, 2, 3, 4], \"color\": \"g\"},\n",
        "    \"index\": {\"ids\": [0, 5, 6, 7, 8], \"color\": \"c\"},\n",
        "    \"middle\": {\"ids\": [0, 9, 10, 11, 12], \"color\": \"b\"},\n",
        "    \"ring\": {\"ids\": [0, 13, 14, 15, 16], \"color\": \"m\"},\n",
        "    \"little\": {\"ids\": [0, 17, 18, 19, 20], \"color\": \"r\"},\n",
        "}\n",
        "test_data = dataset.HandDataset(data_root=data_root, mode='test')\n",
        "test_loader = DataLoader(test_data, batch_size=5, shuffle=False)\n",
        "img, cm_target, img_name, w, h= next(iter(test_loader))\n",
        "    # ***************** draw Limb map *****************\n",
        "def plot_hand(hand_points, colormap, image):\n",
        "    # Create the hand plot\n",
        "    fig, ax = plt.subplots()\n",
        "    for finger in colormap:\n",
        "        # Get the keypoint IDs and color for each finger\n",
        "        ids = colormap[finger]['ids']\n",
        "        color = colormap[finger]['color']\n",
        "        # Get the x and y coordinates for each keypoint\n",
        "        x = [hand_points[i][0] for i in ids]\n",
        "        y = [hand_points[i][1] for i in ids]\n",
        "        # Draw lines between the keypoints for each finger\n",
        "        ax.plot(x, y, color=color, linewidth=2)\n",
        "        # Draw each keypoint with the corresponding finger color and a black border\n",
        "        ax.scatter(x, y, s=50, color=color, edgecolor='k')\n",
        "\n",
        "    # Overlay the plot onto the image\n",
        "    ax.imshow(image)\n",
        "    ax.set_aspect('equal', 'box')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "  all_pred_labels = {}\n",
        "  all_target_labels = {}\n",
        "  model.eval()\n",
        "  if cuda:\n",
        "    img = img.cuda()\n",
        "  cm_pred = model(img)\n",
        "  dictionary_target= get_pred_coordinates(cm_target.cpu(),img_name, w, h, all_target_labels)\n",
        "  dictionary_pred=get_pred_coordinates(cm_pred.cpu(),img_name, w, h, all_pred_labels)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qUxKUUQp5fi6"
      },
      "source": [
        "### Etiquetas reales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1OwEgvUT5c8v"
      },
      "outputs": [],
      "source": [
        "for i,values in enumerate(dictionary_target.values()):\n",
        "  image = Image.open(os.path.join(data_root, 'imgs', img_name[i]))\n",
        "  true_keypoints_img = list(values.values())[0]\n",
        "  plot_hand(true_keypoints_img, COLORMAP, image)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "HK1wLKsq5mY1"
      },
      "source": [
        "### Etiquetas predecidas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJJOS4KV5qMZ"
      },
      "outputs": [],
      "source": [
        "for i,values in enumerate(dictionary_pred.values()):\n",
        "  image = Image.open(os.path.join(data_root, 'imgs', img_name[i]))\n",
        "  pred_keypoints_img = list(values.values())[0]\n",
        "  plot_hand(pred_keypoints_img, COLORMAP, image)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
